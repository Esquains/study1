testBlocks
graph(%a : Tensor
      %b : Tensor
      %c : Tensor) {
  %2 : int = prim::Constant[value=1]()
  %3 : Tensor = aten::add(%a, %b, %2)
  %5 : Tensor = prim::If(%c)
    block0() {
      %6 : int = prim::Constant[value=1]()
      %7 : Tensor = aten::add(%3, %3, %6)
      -> (%7)
    }
    block1() {
      %8 : int = prim::Constant[value=1]()
      %9 : Tensor = aten::add(%b, %3, %8)
      %10 : int = prim::Constant[value=1]()
      %11 : Tensor = aten::add(%9, %3, %10)
      -> (%11)
    }
  %12 : int = prim::Constant[value=1]()
  %13 : Tensor = aten::add(%5, %3, %12)
  return (%13);
}

graph(%a : Tensor
      %b : Tensor
      %c : Tensor) {
  %2 : int = prim::Constant[value=1]()
  %3 : Tensor = aten::add(%a, %b, %2)
  %5 : Tensor = prim::If(%c)
    block0() {
      %8 : int = prim::Constant[value=1]()
      %9 : Tensor = aten::add(%b, %3, %8)
      %10 : int = prim::Constant[value=1]()
      %11 : Tensor = aten::add(%9, %3, %10)
      -> (%11)
    }
  %12 : int = prim::Constant[value=1]()
  %13 : Tensor = aten::add(%5, %3, %12)
  return (%13);
}

graph(%a : Tensor
      %b : Tensor
      %c : Tensor) {
  %3 : int = prim::Constant[value=1]()
  %4 : Tensor = aten::add(%a, %b, %3)
  %5 : Tensor = prim::If(%c)
    block0() {
      %6 : int = prim::Constant[value=1]()
      %7 : Tensor = aten::add(%b, %4, %6)
      %8 : int = prim::Constant[value=1]()
      %9 : Tensor = aten::add(%7, %4, %8)
      -> (%9)
    }
  %10 : int = prim::Constant[value=1]()
  %11 : Tensor = aten::add(%5, %4, %10)
  return (%11);
}

testCreateAutodiffSubgraphs
graph(%0 : Tensor
      %1 : Tensor
      %2 : Tensor
      %3 : Tensor
      %4 : Tensor) {
  %7 : int = prim::Constant[value=1]()
  %23 : Tensor, %24 : Tensor = prim::DifferentiableGraph_0(%2, %1, %4, %0, %3)
  return (%23, %24);
}
with prim::DifferentiableGraph_0 = graph(%13 : Tensor
      %32 : Tensor
      %33 : Tensor
      %35 : Tensor
      %36 : Tensor) {
  %37 : Tensor = aten::mm(%35, %36)
  %34 : Tensor = aten::mm(%32, %33)
  %30 : int = prim::Constant[value=1]()
  %31 : Tensor = aten::add(%37, %34, %30)
  %24 : Tensor, %25 : Tensor, %26 : Tensor, %27 : Tensor = prim::ConstantChunk[chunks=4, dim=1](%31)
  %22 : Tensor = aten::sigmoid(%24)
  %20 : Tensor = aten::sigmoid(%27)
  %18 : Tensor = aten::tanh(%26)
  %16 : Tensor = aten::sigmoid(%25)
  %14 : Tensor = aten::mul(%16, %13)
  %11 : Tensor = aten::mul(%22, %18)
  %8 : Tensor = aten::add(%14, %11, %30)
  %4 : Tensor = aten::tanh(%8)
  %2 : Tensor = aten::mul(%20, %4)
  return (%2, %8);
}

testDifferentiate
graph(%0 : Float(2, 3, 4)
      %1 : Float(2, 3, 4)) {
  %2 : Float(2, 3, 4) = aten::mul(%0, %1)
  %3 : Float(2, 3, 4) = aten::mul(%2, %0)
  %4 : int = prim::Constant[value=1]()
  %7 : int[] = aten::size(%3)
  %5 : Float(2, 3, 4) = aten::add(%3, %1, %4)
  return (%5, %2, %7);
}
graph(%0 : Float(2, 3, 4)
      %1 : Float(2, 3, 4)
      %2 : Float(2, 3, 4)
      %3 : Float(2, 3, 4)
      %4 : Float(2, 3, 4)
      %5 : int[]) {
  %7 : int = prim::Constant[value=1]()
  %6 : int[] = aten::size(%3)
  %8 : Tensor, %9 : Tensor = prim::GradOf[name="aten::add"](%0)
    block0() {
      %10 : Tensor = prim::SumToSize(%0, %5)
      %11 : Float(2, 3, 4) = aten::mul(%0, %7)
      %12 : Tensor = prim::SumToSize(%11, %6)
      -> (%10, %12)
    }
  %13 : Tensor, %14 : Tensor = prim::GradOf[name="aten::mul"](%8)
    block0() {
      %15 : Tensor = aten::mul(%8, %2)
      %16 : Tensor = aten::reduce_as(%15, %4)
      %17 : Tensor = aten::mul(%8, %4)
      %18 : Tensor = aten::reduce_as(%17, %2)
      -> (%16, %18)
    }
  %19 : Tensor = prim::AutogradAdd(%1, %13)
  %20 : Tensor, %21 : Tensor = prim::GradOf[name="aten::mul"](%19)
    block0() {
      %22 : Tensor = aten::mul(%19, %3)
      %23 : Tensor = aten::reduce_as(%22, %2)
      %24 : Tensor = aten::mul(%19, %2)
      %25 : Tensor = aten::reduce_as(%24, %3)
      -> (%23, %25)
    }
  %26 : Tensor = prim::AutogradAdd(%14, %20)
  %27 : Tensor = prim::AutogradAdd(%9, %21)
  return (%26, %27);
}

testDifferentiateWithRequiresGrad
graph(%0 : Float(*)
      %1 : Float(*)) {
  %2 : Float(*) = aten::mul(%1, %1)
  %3 : int = prim::Constant[value=1]()
  %4 : Float(*) = aten::add(%2, %1, %3)
  %6 : Float(*) = aten::add(%4, %0, %3)
  %7 : Float(*) = aten::mul(%6, %0)
  %11 : int[] = aten::size(%7)
  %9 : Float(*) = aten::add(%7, %1, %3)
  return (%4, %9, %6, %11);
}
graph(%0 : Float(*)
      %1 : Float(*)
      %2 : Float(*)
      %3 : Float(*)
      %4 : int[]) {
  %6 : int = prim::Constant[value=1]()
  %5 : int[] = aten::size(%2)
  %7 : Tensor = prim::GradOf[name="aten::add"](%0)
    block0() {
      %8 : Tensor = prim::SumToSize(%0, %4)
      -> (%8)
    }
  %9 : Tensor, %10 : Tensor = prim::GradOf[name="aten::mul"](%7)
    block0() {
      %11 : Tensor = aten::mul(%7, %2)
      %12 : Tensor = aten::reduce_as(%11, %3)
      %13 : Tensor = aten::mul(%7, %3)
      %14 : Tensor = aten::reduce_as(%13, %2)
      -> (%12, %14)
    }
  %15 : Tensor = prim::AutogradAdd(%1, %9)
  %16 : Tensor = prim::GradOf[name="aten::add"](%15)
    block0() {
      %17 : Tensor = aten::mul(%15, %6)
      %18 : Tensor = prim::SumToSize(%17, %5)
      -> (%18)
    }
  %19 : Tensor = prim::AutogradAdd(%10, %16)
  return (%19);
}

