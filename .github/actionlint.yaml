self-hosted-runner:
  labels:
    # GitHub hosted x86 Linux runners
    - linux.20_04.4x
    - linux.20_04.16x
    # Repo-specific LF hosted ARC runners
    - linux.large.arc
    # Organization-wide AWS Linux Runners
    - linux.large
    - linux.2xlarge
    - linux.4xlarge
    - linux.12xlarge
    - linux.24xlarge
    - linux.arm64.2xlarge
<<<<<<< HEAD
=======
    - linux.arm64.2xlarge.ephemeral
    - linux.arm64.m7g.4xlarge
    - linux.arm64.m7g.4xlarge.ephemeral
>>>>>>> 78128cbdd8d ([CD] Use ephemeral arm64 runners for nightly and docker builds (#134473))
    - linux.4xlarge.nvidia.gpu
    - linux.8xlarge.nvidia.gpu
    - linux.16xlarge.nvidia.gpu
    - linux.g5.4xlarge.nvidia.gpu
    - am2.linux.large
    - am2.linux.2xlarge
    - am2.linux.4xlarge
    - am2.linux.12xlarge
    - am2.linux.24xlarge
    - am2.linux.arm64.2xlarge
    - am2.linux.4xlarge.nvidia.gpu
    - am2.linux.8xlarge.nvidia.gpu
    - am2.linux.16xlarge.nvidia.gpu
    - am2.linux.g5.4xlarge.nvidia.gpu
    # Organization-wide AWS Linux Runners on Linux Foundation account
    - lf.linux.large
    - lf.linux.2xlarge
    - lf.linux.4xlarge
    - lf.linux.12xlarge
    - lf.linux.24xlarge
    - lf.linux.arm64.2xlarge
    - lf.linux.4xlarge.nvidia.gpu
    - lf.linux.8xlarge.nvidia.gpu
    - lf.linux.16xlarge.nvidia.gpu
    - lf.linux.g5.4xlarge.nvidia.gpu
<<<<<<< HEAD
=======
    # Organization-wide AWS Linux Runners with new Amazon 2023 AMI
    - amz2023.linux.large
    - amz2023.linux.2xlarge
    - amz2023.linux.4xlarge
    - amz2023.linux.12xlarge
    - amz2023.linux.24xlarge
    - amz2023.linux.arm64.2xlarge
    - amz2023.linux.arm64.m7g.4xlarge
    - amz2023.linux.arm64.m7g.4xlarge.ephemeral
    - amz2023.linux.4xlarge.nvidia.gpu
    - amz2023.linux.8xlarge.nvidia.gpu
    - amz2023.linux.16xlarge.nvidia.gpu
    - amz2023.linux.g5.4xlarge.nvidia.gpu
    # Pytorch/pytorch AWS Linux Runners with the new Amazon 2023 AMI on Linux Foundation account
    - amz2023.lf.linux.large
    - amz2023.lf.linux.2xlarge
    - amz2023.lf.linux.4xlarge
    - amz2023.lf.linux.12xlarge
    - amz2023.lf.linux.24xlarge
    - amz2023.lf.linux.arm64.2xlarge
    - amz2023.lf.linux.4xlarge.nvidia.gpu
    - amz2023.lf.linux.8xlarge.nvidia.gpu
    - amz2023.lf.linux.16xlarge.nvidia.gpu
    - amz2023.lf.linux.g5.4xlarge.nvidia.gpu
>>>>>>> 78128cbdd8d ([CD] Use ephemeral arm64 runners for nightly and docker builds (#134473))
    # Repo-specific IBM hosted S390x runner
    - linux.s390x
    # Organization wide AWS Windows runners
    - windows.4xlarge.nonephemeral
    - windows.8xlarge.nvidia.gpu
    - windows.8xlarge.nvidia.gpu.nonephemeral
    - windows.g5.4xlarge.nvidia.gpu
    # Organization-wide AMD hosted MI300 runners
    - linux.rocm.gpu
    # Repo-specific Apple hosted  runners
    - macos-m1-ultra
    - macos-m2-14
    # Org wise AWS `mac2.metal` runners (2020 Mac mini hardware powered by Apple silicon M1 processors)
    - macos-m1-stable
    - macos-m1-13
    - macos-m1-14
    # GitHub-hosted MacOS runners
    - macos-latest-xlarge
    - macos-13-xlarge
    - macos-14-xlarge
